\PassOptionsToPackage{svgnames}{xcolor}
\documentclass[12pt]{article}



\usepackage[margin=1in]{geometry}  
\usepackage{graphicx}             
\usepackage{amsmath}              
\usepackage{amsfonts}              
\usepackage{framed}               
\usepackage{amssymb}
\usepackage{array}
\usepackage{amsthm}
\usepackage[nottoc]{tocbibind}
\usepackage{bm}
\usepackage{enumitem}
\usepackage{mathtools}
\DeclarePairedDelimiter\ceil{\lceil}{\rceil}
\DeclarePairedDelimiter\floor{\lfloor}{\rfloor}

  \newcommand\norm[1]{\left\lVert#1\right\rVert}
\setlength{\parindent}{0cm}
\setlength{\parskip}{0em}
\newcommand{\Lim}[1]{\raisebox{0.5ex}{\scalebox{0.8}{$\displaystyle \lim_{#1}\;$}}}
\newtheorem{definition}{Definition}[section]
\newtheorem{theorem}{Theorem}[section]
\newtheorem{notation}{Notation}[section]
\theoremstyle{definition}
\DeclareMathOperator{\arcsec}{arcsec}
\DeclareMathOperator{\arccot}{arccot}
\DeclareMathOperator{\arccsc}{arccsc}
\DeclareMathOperator{\spn}{Span}
\DeclareMathOperator{\perm}{P}
\DeclareMathOperator{\combi}{C}
\setcounter{tocdepth}{1}
\begin{document}

\title{Revision notes - MA3269}
\author{Ma Hongqiang}
\maketitle
\tableofcontents

\clearpage
%\twocolumn
\section{Counting}
\subsection{Geometric and Arithmetic Series}
\begin{definition}[Geometric series]
\hfill\\\normalfont A \textbf{geometric series} is a sum of the form
\[
a+ar+ar^2+\cdots+ar^n
\]
\end{definition}
\begin{theorem}[Sum of Geometric series]
\hfill\\\normalfont The value of sum of a geometric series up to $n$th term, $G_n$, for $r\neq 1$, is given by the formula
\[
G_n = a\frac{r^{n+1}-1}{r-1}
\]
\end{theorem}
The following is an example of solving generating functions of an infinite sequence.\\
Suppose $a_0 = 1, a_1 = 1, a_2 = 3$. Also, the recurrence relation of the sequence is $a_n = 2a_{n-1}+1$.
Define the \textbf{generating function} $U(x)$ as follows,

\begin{align*}
U(t)&:=\sum_{n=0}^\infty a_nt^n\;\;\;\;(|t|<1)\\
&=t+\sum_{n=2}^\infty a_nt^n\\
&=t+\sum_{n=2}^\infty (2a_{n-1}+1)t^n\\
&=t+\sum_{n=2}^\infty t^n+2t\sum_{n=2}^\infty a_{n-1}t^{n-1}\\
&=\sum_{n=1}^\infty t^n +2t\sum_{n=1}^\infty a_nt^n\\
&=\sum_{n=0}^\infty t^n-1+2t\sum_{n=0}^\infty a_nt^n\\
&=\sum_{n=0}^\infty t^n-1+2tU(t)\\
&=\frac{1}{1-t}-1+2tU(t)
\end{align*}

Solving $U(t)$ and partial fractioning, we have

\begin{align*}
U(t) &= \frac{1}{1-2t} - \frac{1}{1-t}\\
&=\sum_{n=0}^\infty (2t)^n -\sum_{n=0}^\infty t^n\\
&=\sum_{n=0}^\infty (2^n-1)t^n
\end{align*}

By definition,
\[
U(t)=\sum_{n=0}^\infty a_nt^n = \sum_{n=0}^\infty (2^n-1)t^n
\]
Hence,
\[
a_n = 2^n - 1
\]
\begin{theorem}[Trianglar Number]
\[
T_n = 1+2+3+\cdots+n = \frac{1}{2}n(n+1)
\]
\end{theorem}
\begin{definition}[Arithmetic series]
\hfill\\\normalfont More generally, an \textbf{arithmetic series} is a sum of the form
\[
a+(a+d)+(a+2d)+\cdots+(a+nd)
\]
The number $a$ is called the \textbf{first term} and the number $d$ is called the \textbf{common difference} of the arithmetic series.
\end{definition}
\begin{theorem}[Sum of arithmetic series]
\hfill\\\normalfont The sum of an arithmetic series, up to $n$th term, $A_n$ is given by
\[
A_n = \frac{1}{2}(n+1)(2a+dn)
\]
\end{theorem}
\subsection{Sets}
Similar objects are often gathered together for easy reference. Such a collection is called a \textbf{set}.\\
The item in a set are often referred to as \textbf{elements} or \textbf{members} of the set.\\
We exhibit members of a set within parentheses:
\[
S = \{a,e,i,o,u\}\;\;\;\text{or}\;\;\;S=\{x:x \text{ is a vowel of the English alphabet}\}
\]
We use the notation $x\in S$ to mean "$x$\textit{ is }a member of $S$". \\The notation $x\not\in S$means "$x$ \textit{ is not }a member of $S$".
\begin{definition}[Empty Set]
\hfill\\\normalfont The \textbf{empty set} is the set containing \textit{no} members. This is denoted by $\varnothing$. That is
\[
\varnothing = \{\}
\]
\end{definition}
\begin{definition}[Union]
\hfill\\\normalfont The \textbf{union} of sets $A$ and $B$ is the set whose elements are precisely those belong to $A$ or $B$. Symbolically, we denote the union by $A\cup B$:
\[
A\cup B = \{x:x\in A \text{ or } x\in B\}
\]
\end{definition}
\begin{definition}[Intersection]
\hfill\\\normalfont The \textbf{intersection} of sets $A$ and $B$ is the set whose elements are precisely those belong to $A$ and $B$. Symbolically, we denote the intersection by $A\cap B$:
\[
A\cap B = \{x:x\in A \text{ and } x\in B\}
\]
\end{definition}
\begin{definition}[Disjoint Set]
\hfill\\\normalfont Sets $A$ and $B$ are \textbf{disjoint} if
\[
A\cap B = \varnothing
\]
\end{definition}
\begin{theorem}[Properties of union and intersection]
\hfill\\\normalfont
\begin{itemize}
  \item $A\cup B = B\cup A$, $A\cap B = B\cap A$.
  \item $(A\cup B)\cup C = A\cup(B\cup C)$
  \item $(A\cap B)\cap C = A\cap (B\cap C)$
  \item $A\cup(B\cap C) = (A\cup B)\cap (A\cup C)$
  \item $A\cap(B\cup C) = (A\cap C)\cup (A\cap C)$
  \item $A\cup A = A$, $A\cap A = A$
  \item $A\cup \varnothing = A$, $A\cap \varnothing = \varnothing$
\end{itemize}
\end{theorem}
\begin{definition}[Subset]
\hfill\\\normalfont If every element of $A$ is also an element of $B$, then $A$ is a \textbf{subset} of $B$.
\[
A\subseteq B
\]
\end{definition}
Some immediate consequence of the definition of a subset:
\begin{itemize}
  \item For any set $A$, $A\subseteq A$, $\varnothing\subseteq A$.
  \item For sets $A$, $B$,
  \[
A\subseteq A\cup B, \;\;\;A\cap B \subset A
  \]
  \item If $A\subseteq B$, then
  \[
A\cup B = B,\;\;\; A\cap B = A
  \] 
\end{itemize}
We are often interested in subsets of a fixed reference set called the \textbf{unviersal set}, usually denoted by $U$.
\begin{definition}[Complement]
\hfill\\\normalfont Suppose $U$ is the given universal set, and $A\subseteq U$. Then the \textbf{complement} of $A$, denoted by $A^c$, is the set consisting of all the elements of $U$ which are not in $A$. That is
\[
A^c = \{x\in U: x\not\in A\}
\] 
\end{definition}
By definition,
\[
A\cup A^c = U,\;\;\; A\cap A^c = \varnothing
\]
\begin{theorem}[de Morgan's laws]
\hfill\\\normalfont The following properties hold for set $A$,$B$.
\begin{itemize}
  \item $(A\cup B)^c = A^c\cap B^c$
  \item $(A\cap B)^c = A^c\cup B^c$
\end{itemize}
\end{theorem}
\begin{theorem}[Principle of Inclusion and Exclusion]
\begin{equation*}
\begin{aligned}
P(A_1\cup A_2\cup \cdots\cup A_n)=&\sum_{i=1}^n P(A_i) -\sum_{1\leq i_1\leq i_2\leq n}P(A_{i_1}A_{i_2})+\cdots\\&+(-1)^{r+1}\sum_{1\leq i_1\leq\cdots\leq i_r\leq n}P(A_{i_1}\cdots A_{i_r})\\&+\cdots+(-1)^{n+1}P(A_1\cdots A_n)
\end{aligned}
\end{equation*}
\end{theorem}
\begin{definition}[Floor function]
\hfill\\\normalfont For any real number $x$, the \textbf{floor} of $x$, denoted by
\[
\floor*{x}
\]
is the largest integer $\leq x$.
\end{definition}
\begin{definition}[Ceiling function]
\hfill\\\normalfont For any real number $x$, the \textbf{ceiling} of $x$, denoted by
\[
\ceil*{x}
\]
is the smallest integer $\geq x$.
\end{definition}
\begin{theorem}[Number of multiples]
\hfill\\\normalfont Let $i$ and $n$ be positive integers. The number of multiples of $i$ among the integers $1,2,\ldots, n$ is 
\[
\floor*{\frac{n}{i}}
\]
\end{theorem}
\subsection{Counting Principles}
\begin{theorem}[Addition Principle]
\hfill\\\normalfont If a choice from set $A_i$ can be made in $n_i$ ways for $i = 1,\ldots, m$, then the number of choices from $A_1\cup \cdots\cup A_m$ is
\[
n_1+\cdots+n_m
\]
\textbf{Necessary condition}: The sets $A_1,\ldots,A_m$ are \textbf{pairwise/mutually disjoint}, i.e. $A_i\cap A_j = \varnothing$ for all $i\neq j$.
\end{theorem}
\begin{theorem}[Multiplication Principle]
\hfill\\\normalfont If a task involves a sequence of $m$ steps, where the $i$th step can be completed in $n_i$ ways, then there are
\[
n_1\times \cdots n_m
\]
ways to complete the task.\\
\textbf{Necessary condition:} The ways each step can be completed are \textbf{indepedent} of each other.
\end{theorem}
\subsection{Arrangements and Combinations}
\begin{theorem}
\hfill\\\normalfont Let $^n\perm_k$ be the number of ways of arranging, in a row, $k$ \textit{different} objects taken from $n$ \textit{different} objects. Then
\[
^n\perm_k = \frac{n!}{(n-k)!}
\]
\end{theorem}
\begin{theorem}
\hfill\\\normalfont The number of ways of arranging in a row $n_1$ \textit{identical} objects of Type 1, $n_2$ identical objects of Type 2, $\ldots$, and $n_k$ identical objects of Type $k$, is equal to
\[
\frac{(\sum_{i=1}^kn_i)!}{\prod_{i=1}^kn_i!}
\]
\end{theorem}
\begin{theorem}[Circular Arrangements]
\hfill\\\normalfont The number of ways of arranging $n$ different objects in a circle is
\[
(n-1)!
\]
\end{theorem}
\begin{theorem}
\hfill\\\normalfont Let $^n\combi_k$ denote the number of ways of choosing $k$ objects from a set of $n$ different objects. Then
\[
^n\combi_k = \frac{n!}{k!(n-k)!}
\]
\end{theorem}
Another notation for $^n\combi_k$ is $\binom{n}{k}$.
\begin{theorem}[Simple properties of binomial coefficients]
\hfill\\\normalfont
\begin{itemize}
  \item $\binom{n}{0}=\binom{n}{n}=1$
  \item $\binom{n}{k}=\binom{n}{n-k}$
  \item $\sum_{i = 0}^n\binom{n}{i}=2^n$
\end{itemize}
\end{theorem}
\subsection{Number of Routes on Rectangular Grid}
\begin{theorem}\hfill\\\normalfont On a rectangular grid, the number of routes from $(i,j)$ to $(k,l)$ moving easterly or notherly without back-tracking is
\[
\frac{((k-i)+(l-j))!}{(k-i)!(l-j)!}=\binom{k+l-i-j}{k-i}=\binom{k+l-i-j}{l-j}
\]
\end{theorem}
\subsection{Pigeonhole Principle}
\begin{theorem}[Pigeonhole Principle]\hfill\\\normalfont
Suppose $m$ objects are distributed among $n$ pigeonholes. If $m>n$, then there is at least \textbf{one} pigeonhole with at least \textbf{two} of the distributed objects.
\end{theorem}
\begin{theorem}[Extended Pigeonhole Principle]\hfill\\\normalfont
If $m$ objects are distributed among $n$ pigeonholes and $m>n$, then there will be \textbf{one} pigeonhole which contains \textbf{at least} $\ceil*{\frac{m}{n}}$ objects.
\end{theorem}
\clearpage
\section{Graphing}
\subsection{Introduction}
\begin{definition}[Graph]
\hfill\\\normalfont A \textbf{graph} is a collection of points and lines connecting \textit{some pairs} of the points.\\
The points are called the \textbf{vertices}.\\
The lines joining any the vertices are called \textbf{edges}.
\end{definition}
Two vertices that are joined by an edge are called \textbf{adjacent} vertices.
\begin{definition}[Simple Graph]
\hfill\\\normalfont A graph without loops and multiple edges is called a \textbf{simple graph}.
\end{definition}
\subsection{Basic Technology}
\begin{definition}[Walk]
\hfill\\\normalfont A \textbf{walk} is a sequence of vertices and edges in a graph such that
\begin{itemize}
  \item the sequence alternates between vertices and edges, starting and ending with vertices; and
  \item each edge in the sequence joins the vertices that occur immediately before and after it in the sequence
\end{itemize}
\end{definition}
A walk that starts and ends at \textit{different} vertices is called an \textbf{open walk}.\\
A walk that starts and ends at \textit{the same} vertex is called a \textbf{closed walk}.\\
A walk that contains \textit{no repeated} vertices \textit{and} edges is called a \textbf{path}.
\begin{definition}[Cycle]
\hfill\\\normalfont A \textbf{cycle} in a graph is a \textbf{closed walk} in which the only repitition is the \textbf{first and last} vertex.
\end{definition} 
\begin{definition}[Length]
\hfill\\\normalfont The \textbf{length} of a walk is defined as the number of edges in the walk, including repetitions.
\end{definition}
\begin{definition}[Degree]
\hfill\\\normalfont The \textbf{degree} of a vertex in a graph is the number of edges that occur at that vertex, with every \textit{loop counted as two}.
\end{definition}
\begin{theorem}[Degree Theorem]
\hfill\\\normalfont In any graph, the sum of all the degrees is equal to \textbf{twice} the number of edges.\\In particular, the sum of all the degrees must be even.
\end{theorem}
\begin{definition}[Odd and Even Vertex]
\hfill\\\normalfont An \textbf{odd} vertex is a vertex whose degree is an odd number.\\
An \textbf{even} vertex is a vertex whose degree is an even number.
\end{definition}
\begin{definition}[Minimum and Maximum Degree]
\hfill\\\normalfont In any graph $G$, the symbol $\delta(G)$ represents the \textbf{minimum} degree in $G$; the symbol $\Delta(G)$ represents the maximum degree.
\end{definition}
\subsection{Trees}
\begin{definition}[Trees]
\hfill\\\normalfont A \textbf{tree} is a simple graph that is connected and contains no cycle.
\end{definition}
\begin{definition}[Leaf]
\hfill\\\normalfont A \textbf{leaf} is a vertex of degree 1.
\end{definition}
\begin{theorem}[Leaf Lemma]
\hfill\\\normalfont Every tree with two or more vertices has at least two vertices of degree 1.
\end{theorem}
\begin{theorem}[Tree theorem]
\hfill\\\normalfont Every tree with $n$ vertices has exactly $n-1$ edges.
\end{theorem}
\subsection{Minimal Spanning Trees}
\begin{definition}[Weighted Graphs]
\hfill\\\normalfont A \textbf{weighted graph} is a graph in which each edge has a number associated with it, which we refer to as the \textbf{weight} of that edge.
\end{definition}
\begin{definition}[Subgraph]
\hfill\\\normalfont A \textbf{subgraph} of a graph $G$ is a graph $H$ whose vertices and edges are taken from those of $G$.
\end{definition}
\begin{definition}[Weight of a graph]
\hfill\\\normalfont The \textbf{weight} of a graph $G$ is the sum of weights of all its edges. Symbolically,
\[
w(G) = \sum_{e\text{ edge of }G}w(e)
\]
where $w(e)$ denotes the weight of the edge $e$.
\end{definition}
\begin{definition}[Spanning Tree]
\hfill\\\normalfont A \textbf{spanning tree} of a given graph $G$ is a subgraph $T$ of $G$ which is a tree and it contains \textbf{all} the vertices of $G$.
\end{definition}
\begin{definition}[Minimal Spanning Tree]
\hfill\\\normalfont A \textbf{minimal spanning tree} of $G$ is a spanning tree which has the \textit{minimum weight} among all the spanning trees of $G$.
\end{definition} 
\begin{theorem}[Prim's algorithm]
\hfill\\\normalfont \textbf{Prim's Algorithm} is a procedure for constructing a minimal spanning tree in a given weighted graph:\\
\textbf{Input}: a weighted graph $G$\\
\textbf{Output}: a minimal spanning tree $T$ of $G$\\
\textbf{Algorithm:}
\begin{itemize}
  \item Start with any vertex and select an edge having the minimum weight among all the edges at that vertex
  \item Consider \textit{all} edges that go from each vertex already reached to a new vertex.\\Select one that has \textit{minimum weight}.
  \item Continue until all vertices have been reached.
\end{itemize}
\end{theorem}
\subsection{Euler Walks}
In this section, we allow graphs to contain loops and multiple edges.
\begin{definition}[Directed graph] 
\hfill\\\normalfont A \textbf{directed graph} is a graph in which \textit{every} edge is assigned a direction indicated by an arrow(called a \textbf{directed edge}).
\end{definition}
\begin{definition}[Walk in directed graph]
\hfill\\\normalfont A \textbf{walk} in a directed graph is a sequence of vertices and directed edges such that
\begin{itemize}
  \item the sequence alternates between vertices and directed edges, starting and ending with vertices; and
  \item each directed edge in the sequence joins the vertices that occur immediately before and after it in the sequence \textbf{in the direction} indicated by the arrow of the directed edge.
\end{itemize}
\end{definition}
\begin{definition}[Euler walk]
\hfill\\\normalfont An \textbf{Euler walk} in a graph is a walk that uses every edge in the graph exactly once.\\
A \textbf{closed} Euler walk (also known as \textbf{Euler circuit}) is an Euler walk that starts and ends at the same vertex.\\
An \textbf{open} Euler walk is an Euler walk that starts and ends at different vertices.
\end{definition}
\textbf{Note:} When tracing an Euler walk,
\begin{itemize}
  \item a vertex may be visited more than once
  \item every edge is visited exactly once
  \item the entire graph is traced without lifting the pen
\end{itemize}
\begin{theorem}[Euler Walk Theorem I]
\hfill\\\normalfont A connected \textit{undirected} graph contains a \textit{closed} Euler walk if and only if \textit{every} vertex has \textbf{even} degree. 
\end{theorem} 
\begin{theorem}[Euler Walk Theorem II]
\hfill\\\normalfont A connected \textit{undirected} graph contains an \textit{open} Euler walk starting from vertex $A$ and ending at vertex $B$ if and only if
\begin{itemize}
  \item vertices $A$ and $B$ have odd degree; and
  \item all the other vertices have even degree.
\end{itemize}
\end{theorem}
\begin{theorem}[Euler Walk Theorem I -- directed version]
\hfill\\\normalfont A connected directed graph contains a \textit{closed} Euler walk if and only if for \textit{every} vertex the number of arrows pointing \textbf{in} is \textit{equal} to the number of arrows pointing \textbf{out}.
\end{theorem}
\begin{theorem}[Euler Walk Theorem II -- directed version]
\hfill\\\normalfont A connected directed graph contains an \textit{open} Euler walk starting from vertex $A$ and ending at vertex $B$ if and only if
\begin{itemize}
  \item for vertex $A$, the number of arrows pointing out is exactly one more than the number of arrows pointing in;
  \item for vertex $B$, the number of arrows pointing in is exactly one more than the number of arrows pointing out;
  \item for all other vertices, the number of arrows pointing in is equal to the number of arrows pointing out.
\end{itemize}
\end{theorem}
\fbox{
\begin{minipage}{\textwidth}
  \textbf{An algorithm} to construct an Euler circuit:
  \begin{enumerate}[label = (\arabic*)]
    \item Make sure the graph is connected and all vertices are even.
    \item Start anywhere. Construct a closed walk without repeated edges.
    \item If the closed walk covers all edges, DONE.
    \item If not, construct another closed walk without repeated edges and combine the two to get a bigger closed walk.
    \item Repeat (4) and stop when all edges are used
\end{enumerate}
\end{minipage}
}
\fbox{
  \begin{minipage}{\textwidth}
  \textbf{Chinese Postman Problem}:\\
  Given a connected weighted graph or directed graph $G$, find the shortest circuit that uses each edge in $G$ \textbf{at least once}.
  \end{minipage}
}
\textbf{The simplest case:}
This occurs when every vertex in the graph has even degree, for in this case an Euler
circuit solves the problem. 
\textbf{General case: Vertices of odd degree present}
\begin{enumerate}
  \item List all odd vertices
  \item List all possible pairing of odd vertices
  \item For each pairing, find paths that connect the vertices with the minimum weight. Find the pairings such that the sum of the weights is minimised.
  \item On the original graph, add the edges that have been found in Step 3
  \item The length of an optimal Chinese postman route is the sum of all the edges added to the total found in Step 4
  \item A route corresponding to this minimum weight is an Euler circuit in the graph obtained in Step 5.
\end{enumerate}
\subsection{Vertex Coloring}
\begin{definition}[Proper Vertex Coloring]
\hfill\\\normalfont A \textbf{proper vertex coloring} of a graph is an assignment of a color to each vertex of the graph in such a way that any two vertices that are adjacent have \textit{different} colours.
\end{definition}
\begin{definition}[Minimal Proper Vertex Coloring]\hfill\\\normalfont
We are interested in a proper vertex coloring of a given graph $G$ using the smallest possible number of colors. Such a coloring is called a \textbf{minimal proper vertex coloring} of $G$.\\
The number of colors that occurs in a minimal proper vertex coloring is called the \textbf{chromatic number} of $G$, denoted by
\[
\chi(G)
\]
\end{definition}
\begin{definition}[Complete Graph]
\hfill\\\normalfont The \textbf{complete graph} on $n$ vertices is a graph on $n$ vertices such that any two vertices are joined by an edge. It is denoted by $K_n$.
\end{definition}
\begin{theorem}[Vertex Coloring Theorem]
\hfill\\\normalfont If a graph $G$ contains a complete graph on $n$ vertices, then a proper vertex coloring of $G$ must use at least $n$ colors. Therefore, $\chi(G)\geq n$.
\end{theorem}
\begin{definition}[Cycle Graph]
\hfill\\\normalfont A \textbf{cycle graph} of length $n$ is denoted by $C_n$.
\end{definition}
\begin{theorem}[Vertex Coloring Theorem II]
\hfill\\\normalfont If a graph $G$ contains a cycle graph $C_n$ on $n$ vertices where $n$ is odd, then a proper vertex coloring of $G$ must use at least 3 colours. Therefore, $\chi(G)\geq 3$.
\end{theorem}
\begin{theorem}[Upper bound algorithm for $\chi$]
\hfill\\\normalfont 
\begin{enumerate}
  \item Arrange the degrees of a graph $G$ in decreasing order:
  \[
  d_1\geq d_2\geq d_3\geq \cdots
  \]
  \item Place the integers $1,2,3,\ldots$ directly under these degrees until you reach an integer $k$ such that $k+1>d_{k+1}$.
\end{enumerate}
Then for this graph $G$, we have
\[
\chi(G)\leq k+1
\]
\end{theorem}
\clearpage
\section{Clocking}
\subsection{Parity of integers}
\begin{definition}[Parity]
\hfill\\\normalfont Two integers are said to be of the same \textbf{parity} if they are either both odd or both even.
\end{definition}
\begin{theorem}[Difference of integers of same parity]
\hfill\\\normalfont If two integers are of the same parity, then their difference is an even integer.
\end{theorem}
\subsection{Congreunce Equations}
\begin{definition}
\hfill\\\normalfont Suppose $a$ and $b$ are integers such that their difference is a multiple of a positive integer $n$. Then we write
\[
a\equiv b \pmod n
\]
where $n$ is called the modulus.
\end{definition}
\begin{theorem}[Properties of modulo arithematic]
\hfill\\\normalfont If the remainder of $a$ when divided by $n$ is $r$, then
\[
a\equiv r \pmod n
\]
$a\equiv b pmod n$ if and only if $a$ and $b$ have the same remainder when divided by $n$.\\
If $a\equiv b\pmod n$, then $a\equiv b\pm n\pmod n$.\\
Suppose $a\equiv b\pmod n$, then
\[
ka \equiv kb \pmod n
\]
where $k$ is a integer; and
\[
a^p\equiv b^p\pmod n
\]
where $p$ is a positive integer.\\
Congruences are transitive in a sense that, if $a\equiv b\pmod n$ and $b\equiv c\pmod n$ then
\[
a\equiv c\pmod n
\]
Two congruences with the same modulus can be added to each other or multiplied one by the other.\\Suppose $a\equiv b\pmod n$ and $c\equiv d\pmod n$ then
\begin{align*}
a+c&\equiv b+d\pmod n\\
ac&\equiv bd\pmod n
\end{align*}
\end{theorem}
\begin{theorem}[Congruence mod 9]
\hfill\\\normalfont Let $S$ be the sum of digits of the decimal representation of the positive integer $N$. Then
\[
N\equiv S\pmod 9
\]
\end{theorem}
\begin{theorem}[Checking product]
\hfill\\\normalfont Suppose $A\times B = C$, then
\[
S\times T\equiv U\pmod n
\]
where $S,T,U$ are the sums of digits of $A,B,C$ respectively.
\end{theorem}
\clearpage
\section{Coding}
\subsection{Number representation System}
Number representation systems are covered in \texttt{CS2100 Revision Notes}.
\subsection{Error Detection Code}
\begin{definition}[Weighted Sum]
\hfill\\\normalfont Given the sequence (or word) $S_nS_{n-1}\cdots S_2S_1$, its \textbf{weighted sum} is the sum
\[
\sum_{i=1}^n i\times e_i
\]
where $e_i$ is the numerical value which corresponds to the symbol $S_i, 1\leq i\leq n$.
\end{definition}
\begin{theorem}[Encoding Procedure Modulo 37]
\hfill\\\normalfont
\textbf{Input}: A sequence $\mathbf{S} = S_nS_{n-1}\cdots S_2, n\leq 36$.
\begin{enumerate}
  \item Find the \textit{check digit} $c$ such that
  \[
w(e_ne_{n-1}\cdots e_2c)\equiv 0\;\;\; \mod 37
  \]
  where $w$ denotes the weighted sum.
  \item Find the symbol $S_1$ that corresponds to $c$.
\end{enumerate}
\textbf{Output}: The encoded sequence is
\[
S_nS_{n-1}\cdots S_2S_1
\]
\end{theorem}
\begin{definition}[Error]
\hfill\\\normalfont A word is said to contain $k$ errors if $k$ of its letters are erroneous.
\end{definition}
\begin{theorem}[Error Detection]
\hfill\\\normalfont If $A$ is a correctly encoded word, and during transmission, some errors occur and the word $A^\prime$ is received. The errors in $A^\prime$ is said to be detected if its weighted sum
\[
w(A^\prime)\not\equiv 0\;\;\; \mod 37
\]
\end{theorem}
\begin{theorem}\normalfont In weighted sum encoding modulo 37, if a single error occurs, then it can be detected.
\end{theorem}
\begin{theorem}\normalfont Weighted sum modulo 37 can detect a transposition error.\end{theorem}
\subsection{ISBN}
ISBN is also a encoding scheme with 10 digits which detects the error with module 11, and check digit at last.
\begin{theorem} \normalfont ISBN can detect a single error and a transposition error.\end{theorem}
\subsection{Hamming (7,4) Codes}
Error recovery can be achieved with 
\begin{itemize}
  \item Hamming (7,4) Codeword
  \item Hamming (8,4) Codeword
\end{itemize}
\begin{definition}[Hamming (7,4) Code]
\hfill\\\normalfont Hamming (7,4) Code 
\begin{itemize}
  \item encodes 4 bits (0 or 1) of data into 7 bits by adding 3 \textbf{parity bits}
  \item can \textbf{detect} and \textbf{correct} any single-bit error
  \item can \textbf{detect} but \textit{not} correct a 2-bit error
\end{itemize}
Construction of Hamming Code:\\
\textbf{Input}: 4-bit message $w=s_1s_2s_3s_4$.\\
\textbf{Output}: 7-bit code $h=s_1s_2s_3s_4s_5s_6s_7$, where $s_5,s_6,s_7$ are parity bits defined as follows:
\begin{align*}
s_1+s_3+s_4+s_5&\equiv 0\;\;\;\mod 2\\
s_1+s_2+s_4+s_6&\equiv 0\;\;\;\mod 2\\
s_1+s_2+s_3+s_7&\equiv 0\;\;\;\mod 2
\end{align*}
\begin{figure}[h]
\centering
\includegraphics[width = 0.5\textwidth]{4_1.png}
\end{figure}
The parity bits are defined in such a way that the total number of 1's in \textbf{each} of the circles $A,B,C$ must be \textbf{even}.
\end{definition}
\begin{theorem}\normalfont Hamming (7,4) Code can correct a 1-bit error.
\end{theorem}\clearpage
\begin{table}[h]
\centering
\begin{tabular}{|c|c|}
\hline
Error bit&Parity Check\\\hline
$s_1$&\textbf{All} circles $A,B,C$ \textbf{fail} the parity check\\\hline
$s_2$&\textbf{Only} $B$ and $C$ \textbf{fail} the parity check\\\hline
$s_3$&\textbf{Only} $A$ and $C$ \textbf{fail} the parity check\\\hline
$s_4$&\textbf{Only} $A$ and $B$ \textbf{fail} the parity check\\\hline
$s_5$&\textbf{Only} $A$ \textbf{fails} the parity check\\\hline
$s_6$&\textbf{Only} $B$ \textbf{fails} the parity check\\\hline
$s_7$&\textbf{Only} $C$ \textbf{fails} the parity check\\\hline
no error&\textbf{All} $A, B, C$ \textbf{pass} the parity check\\\hline
\end{tabular}
\end{table}
\begin{theorem}\normalfont For Hamming (7,4) Code, the categories of possible senarios can be classified as follows if there were actually two errors:
\begin{enumerate}
  \item Error in $s_1$ and one of $s_2, s_3,s_4$
  \item Error in $s_1$ and one of $s_5,s_6,s_7$
  \item Error in 2 of $s_2,s_3,s_4$
  \item Error in 2 of $s_5,s_6,s_7$
  \item One error in $s_2,s_3,s_4$ and one error in $s_5,s_6,s_7$.\\There are two typical sub-cases:
  \begin{enumerate}
    \item $s_2,s_5$
    \item $s_2,s_6$
  \end{enumerate}
\end{enumerate}
In each of these, at least one circle fails.
\begin{figure}[h]
\centering
\includegraphics[width=0.6\textwidth]{4_2.png}
\end{figure}
\end{theorem}
Do note that Hamming (7,4) code \textit{cannot} rectify two error bits.
\begin{definition}[Erasure error]
\hfill\\\normalfont Erasure error occurs when there is \textit{no} error in the transmitted word, except that some bits were unrecognisable.
\end{definition}
\begin{theorem}\normalfont Erasure error involving at most 2 bits under Hamming (7,4) Code can \textit{always} be corrected.
\end{theorem}
\subsection{Hamming (8,4) Codes}
\begin{definition}[Hamming (8,4) Code]
\hfill\\\normalfont THe Hamming (8,4) codeword is formed by
\begin{enumerate}
  \item First, take a Hamming (7,4) codeword $s_1s_2s_3s_4s_5s_6s_7$.
  \item Next, add the extra bit $s_8$ so that the total number of $1$'s in the 8-bit word $s_1\ldots s_8$ is even, i.e.
  \[
s_1+\cdots+s_8\equiv 0\;\;\;\mod 2
  \]
\end{enumerate}
The above requirement is known as the \textbf{overall parity check}.
\end{definition}
\begin{theorem}\normalfont If the overall parity check fails, then there is an \textbf{odd} number of errors. If the overall parity check passes, then there is an \textbf{even} number of errors.
\end{theorem}
\begin{theorem}\hfill\\\normalfont The overall parity check can detect an odd number of errors. \\Suppose it is known that the number of errors is at most 2.\\If the overall parity check fails, then there is exactly one error and it can be corrected.\\If the overall parity passes and the parity check fails for at least one of the circles, then there are two errors, but it \textit{cannot} be corrected.\\If all parity checks pass, then there is no error.
\end{theorem}
\clearpage
\section{Enciphering}
\subsection{Early Cryptosystems}
\subsubsection{Transposition and Substitution Systems}
\begin{definition}[Polybius Square]
\hfill\\\normalfont Letters of message are written in $5\times 5$ squares and transposed in a prearranged order.
\end{definition}
\begin{definition}[Caesar's Code]
\hfill\\\normalfont Each letter of the message is replaced by the latter which occupies three positions after the original letter in the natural sequence of the latin alphabet.
\end{definition}
The earliest ciphers are essentially of two types:
\begin{itemize}
  \item \textbf{Transposition System}: This merely rearranges the position of the letters or symbols of the original message according to a prearranged procedure.
  \item \textbf{Substitution System}: This replaces each letter or symbol of the original message by a different letter or symbol according to some rule.
\end{itemize}
\begin{definition}[Generalised Rail Fence Transposition]
\hfill\\\normalfont Generalised Rail Fence Transposition is formed by the following procedure:\\Suppose we form $n$ lines. The $k$-th line $L_k$ consists of all those letters in positions $k, n+k, 2n+k,\ldots$. \\Then juxtapose these $n$ lines of letters into one single line of letters.
\end{definition}
\subsubsection{Shift transformation}
\begin{definition}[Shift Transformation]
\hfill\\\normalfont Shift transformation moves each letter cyclically a fixed number, say $k$, of places forward.\\If we denote $A$ as $0$, till $Z$ as $25$, then shifting $k$ places forward follows the procedure below:
\begin{itemize}
  \item \textbf{Input}: an integer $x$ between $0$ and $25$ inclusive
  \item \textbf{Output}: integer $y$, between $0$ and $25$, satisfying the congruence
  \[
y\equiv x+k \;\;\;\mod 26
  \]
\end{itemize}
\end{definition}
\subsection{Vignere Cipher}
\begin{definition}{Vignere Cipher}\hfill\\\normalfont The Vignere Cipher utilises a $26\times 26$ \textbf{Vignere square} and a \textbf{keyword}. \\
\begin{figure}
\centering
\includegraphics[width = 0.5\textwidth]{5_1.png}
\caption{Vignere Cipher}
\end{figure}
Procedure to encode are as following:\\
\begin{itemize}
  \item Write the keyword repeatedly in a row above the row of the message - one letter of the keyword above one letter of the message. 
  \item For each character in the original message, use itself and the letter of the keyword above to uniquely determines the encoded character.
\end{itemize}
\end{definition}
\subsection{Affine Cryptosystems}
\begin{definition}[Multiplicative Inverse]
\hfill\\\normalfont If $n$ is a positive integer greater than $1$ and $a$ is any integer, then $a$ is said to have a \textbf{multiplicative inverse modulo} $n$ if there is an integer $b$ such that
\[
ab\equiv 1\;\;\;\mod n
\]
\end{definition}
\textbf{Remark}: If $ab\equiv 1\;\mod n$, then $a$ and $b$ form an inversive pair.\\
If $b$ is an inverse, then so is $b+kn$ for any integer $k$.
\begin{definition}[Affine Cryptosystem]
\hfill\\\normalfont An \textbf{affine cryptosystem} is a cryptosystem in which the enciphering transformation is of the form
\[
y=f(x)\equiv ax+b\;\;\;\mod n
\]
where 
\begin{itemize}
  \item $n$ is the total number of letters and symbols that may be used in the plaintext. Usually $n=26$.
  \item $a$ and $b$ are integers.
  \item the pair $(a,b)$ is called the \textbf{key} of the affine cryptosystem.
\end{itemize}
\end{definition}
Specifically, for affine cryptosystems on  a 26-letter alphabet, the following conditions are imposed on the choice of key $(a,b)$:
\begin{itemize}
  \item $0\leq a,b\leq 25$
  \item $a$ is odd and $a\neq 13$.
\end{itemize}
\begin{theorem}[Deciphering transformation of an affine cryptosystem on 26 letters]
\hfill\\\normalfont Suppose the enciphering transformation is given by the definition above, then the deciphering transformation is given by
\[
x=f^{-1}(y)\equiv a^\prime y-a^\prime b\;\;\;\mod 26
\]
where $a^\prime$ is the inverse of $a$ modulo $26$.
\end{theorem}
\subsection{Greatest Common Divisior \& Euclidean Algorithm}
\begin{definition}[Greatest Common Divisor]
\hfill\\\normalfont Let $a$ and $b$ be integers, not both zero. An integer that divides both $a$ and $b$ is a common divisor of $a$ and $b$.\\\textbf{Greatest Common Divisor} of $a$ and $b$, denoted by $\gcd(a,b)$, is the largest common divisor of both $a$ and $b$.
\end{definition}
\begin{theorem}\normalfont Let $a,b,q,r$ be integers such that $a=bq+r$. Then
\[
\gcd(a,b)=\gcd(b,r);
\]
\end{theorem}
\begin{theorem}[Euclidean Algorithm]
\hfill\\\normalfont Given two integers $n$ and $a$, where $0<a<n$, we divide $n$ by $a:=r_0$ and make a series of such divisions of $\frac{r_i}{r_{i+1}}, i=0,1,\ldots$ which eventually terminate with a zero remainder. The $r_i$'s are the remainders. Then we have
\[
\gcd(n,a)=\gcd(a,r_1)=\gcd(r_1,r_2)\cdots=\gcd(r_j, 0)=r_j
\]
\end{theorem}
\textbf{Remark}: The greatest common divisor can be written in the form of $ax+ny$, where $x,y$ are integers determinable from backtracking the Euclidean Algorithm.
\begin{theorem}\normalfont Suppose $a$ has an inverse $b$ modulo $n$. Then $\gcd(a,n)=1$.
\end{theorem}
\begin{theorem}\normalfont Suppose $a,n$ are positive integers. If $\gcd(a,n)=1$, then $a$ has an inverse modulo $n$.
\end{theorem}
\begin{theorem}\normalfont Suppose $a,n$ are positive integers. Then $a$ has an inverse modulo $n$ if and only if $\gcd(a,n)=1$.\end{theorem}
\begin{theorem}[Fermat's Little Theorem]\hfill\\\normalfont Let $p$ be a prime number and $a$ be an integer which is not a multiple of $p$. Then
\[
a^{p-1}\equiv 1\;\;\;\mod p
\]
\end{theorem}
\end{document}